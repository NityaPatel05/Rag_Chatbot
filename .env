# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# RAG Configuration
CHUNK_SIZE=500
CHUNK_OVERLAP=50
RETRIEVER_K=8

# Optional: If you want to use OpenAI instead of Ollama
# OPENAI_API_KEY=your_openai_api_key_here